{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pancreas_CT_2D_3D_segmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MitraDP/Pancreas-CT-image-and-volumetric-segmentation/blob/main/Pancreas_CT_2D_3D_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sbSoQCW4A_Y"
      },
      "source": [
        "#Pancreas Cancer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Af2mQPHUtdF0"
      },
      "source": [
        "##Install the NVIDIA System Management Interface"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4XK-qnwqCHL"
      },
      "source": [
        "!ls -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!nvidia-smi\n",
        "!nvcc --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nt9t2STJTtqa"
      },
      "source": [
        "##Library imports and the environment setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7p__nzdUqCEM"
      },
      "source": [
        "%%capture\n",
        "!pip install pydicom\n",
        "!pip install pillow\n",
        "!pip install torchio\n",
        "!pip install torch-lr-finder\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from collections import OrderedDict\n",
        "import random\n",
        "from random import shuffle\n",
        "\n",
        "import pydicom as dicomio\n",
        "import nibabel as nib\n",
        "\n",
        "import torch\n",
        "import torch.utils.data\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset\n",
        "from torchsummary import summary\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "from torch_lr_finder import LRFinder\n",
        "import albumentations as A\n",
        "import torchio as tio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95_QY3Lu3w-r"
      },
      "source": [
        "#check if CUDA is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available. Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available. Training on GPU ...')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExWu0Uum2nDw"
      },
      "source": [
        "##Set seed for reproducibility\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "set_seed(51)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9vLCU55aFMa"
      },
      "source": [
        "from loss import TverskyLoss\n",
        "from net import UNet_2D, UNet_3D\n",
        "from volume_patch_composer import volume_composer, patch_creator\n",
        "from dataset import Pancreas_2D_dataset, Pancreas_3D_dataset, partitioning\n",
        "from metrics import performance_metrics\n",
        "from train import train_2D, train_3D\n",
        "from inference import get_inference_performance_metrics_2D\n",
        "from inference import get_inference_performance_metrics_3D\n",
        "from inference import  visualize_patient_prediction_2D\n",
        "from inference import visualize_patient_prediction_3D\n",
        "from inference import volume"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lESli3UEup65"
      },
      "source": [
        "##Import the pancreas datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6x9OCMs0uQdA"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysXq5eMvuUbX"
      },
      "source": [
        "%%capture\r\n",
        "#make a directory for the original data\r\n",
        "!mkdir data/\r\n",
        "#make a directory for the resized 3D data\r\n",
        "!mkdir data3D\r\n",
        "#upload CT zip file\r\n",
        "!cp /content/drive/MyDrive/Pancreas-CT.zip /content/\r\n",
        "!unzip   Pancreas-CT.zip\r\n",
        "!rm Pancreas-CT.zip\r\n",
        "!rm -r sample_data\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZszDcwnHuoc_"
      },
      "source": [
        "\"\"\"\r\n",
        "For each patient create 2 folders in the \"data\" directory one for the CT and\r\n",
        "one for the mask.\r\n",
        "\"\"\"\r\n",
        "dir_list = []\r\n",
        "for i in range(1, 83):\r\n",
        "    patient_label = '{:04d}'.format(i)\r\n",
        "    pth = os.path.join('data', 'Patient' + patient_label)\r\n",
        "    dir_list.append(pth)   \r\n",
        "for dir in dir_list:\r\n",
        "    p = dir +'/Masks'\r\n",
        "    os.makedirs(p)\r\n",
        "    p = dir +'/CT'\r\n",
        "    os.makedirs(p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mA5vRlLXIevS"
      },
      "source": [
        "###Load CT (DICOM) and mask (NIfTI) files and save them as png"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geL_fLq76KWb"
      },
      "source": [
        "#The dataset has 82 patient ID/label, e.g. 0057\n",
        "#Upload each patient's annotation folder\n",
        "for i in range(1,83):\n",
        "  patient_label = '{:04d}'.format(i)\n",
        "  pth = os.path.join('/content', 'drive', 'MyDrive', 'Masks', 'label'+ \n",
        "                     patient_label +'.nii.gz')\n",
        "  img = nib.load(pth)\n",
        "  img_data = img.get_fdata()\n",
        "  #load and save patient's annotation slices\n",
        "  for s in range (img_data.shape[2]):\n",
        "    slice_label = '{:03d}'.format(s+1)\n",
        "    slice_img = img_data[:, :, s]\n",
        "    slice_path = os.path.join('/content', 'data', 'Patient' + patient_label,\n",
        "                              'Masks', \"M_\" + slice_label + '.png' )    \n",
        "    cv2.imwrite(slice_path, slice_img)\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgwanA69XITx"
      },
      "source": [
        "#Read each patient's CT slices and save them as pixel arrays\n",
        "#Since the gridsampler samples in C x W x H x D, transpose CT slices. \n",
        "#The dataset has 82 patient ID/label, e.g. 0057\n",
        "for i in range(1,83):\n",
        "  patient_label = '{:04d}'.format(i)\n",
        "  g = glob.glob('/content/Pancreas-CT/PANCREAS_' + patient_label + '/*/*/*.dcm')\n",
        "  #load and save patient's CT slices\n",
        "  for i, f in enumerate(g):\n",
        "    im_label = g[i].split('/')[-1].split('-')[1].split('.')[0]\n",
        "    im_path  = os.path.join('/content', 'data', 'Patient' + patient_label, \n",
        "                            'CT', 'CT_'+ im_label + '.png' )\n",
        "    cv2.imwrite(im_path,dicomio.read_file(g[i]).pixel_array.transpose(1,0))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oycQncHXHxdC"
      },
      "source": [
        "#remove the original CT folder data to save memory\n",
        "!rm -r Pancreas-CT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pU6vJF2v6qLc"
      },
      "source": [
        "###Create path lists and examine patients data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7UQnCMhftRx"
      },
      "source": [
        "patient_path_list = {} #A dictionary of patients CT and Masks paths\n",
        "patient_path_list['CT'] = {} \n",
        "patient_path_list['Masks'] = {}\n",
        "patient_image_cnt_CT = {} #A dictionary of the patient's number of CT slices \n",
        "patient_image_cnt_Mask = {} #A dictionary of the patient's number of Masks slices\n",
        "#The dataset has 82 patient ID/label, e.g. 0057\n",
        "for i in range(1,83):\n",
        "  patient_label = '{:04d}'.format(i)\n",
        "  patient_path_list ['CT']['Patient'+str(patient_label)] \\\n",
        "  = sorted(glob.glob('/content/data/Patient' + patient_label + '/CT/*.png'))        \n",
        "  patient_image_cnt_CT['Patient'+str(patient_label)] \\\n",
        "  = len (patient_path_list ['CT']['Patient'+str(patient_label)])  \n",
        "  patient_path_list ['Masks']['Patient'+str(patient_label)] \\\n",
        "  = sorted(glob.glob('/content/data/Patient' + patient_label + '/Masks/*.png'))   \n",
        "  patient_image_cnt_Mask['Patient'+str(patient_label)] \\\n",
        "  = len (patient_path_list ['Masks']['Patient'+str(patient_label)])  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1yYaDMAg2YU"
      },
      "source": [
        "\"\"\" \n",
        "Identify and remove patients with zero or inconsistent number of CT and mask \n",
        "slices.\n",
        "\"\"\"\n",
        "keys_to_delete = [k for k in patient_image_cnt_CT if patient_image_cnt_CT[k] \\\n",
        "                  != patient_image_cnt_Mask[k] or patient_image_cnt_CT[k]==0 \\\n",
        "                  or patient_image_cnt_Mask[k]==0 ]\n",
        "for k in keys_to_delete:\n",
        "    del patient_image_cnt_CT[k],patient_image_cnt_Mask[k],\n",
        "    patient_path_list['CT'][k], patient_path_list['Masks'][k]\n",
        "\n",
        "patient_cnt = len(patient_path_list['CT'].keys())  #number of patients left"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcAE72Who29Z"
      },
      "source": [
        "#Number of slices per patient statistics\n",
        "a = [*patient_image_cnt_Mask.values()]\n",
        "print('max:', np.max(a), 'mean:', int(np.round(np.mean(a))), 'median:',\n",
        "      int(np.median(a)), 'min:', np.min(a))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dz_b8iE23P_g"
      },
      "source": [
        "##Set the hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIqzyCJv3LSd"
      },
      "source": [
        "#Define the type of segmentation (2D or 3D): bool\r\n",
        "unet_2d = False  \r\n",
        "\r\n",
        "#Volume resize parameters (d1,d2,d3) are (height, width,depth)\r\n",
        "d1 = torch.linspace(-1, 1, 256)\r\n",
        "d2 = torch.linspace(-1, 1, 256)\r\n",
        "d3 = torch.linspace(-1,1, 128)\r\n",
        "\r\n",
        "#Patch parameters for volumetric segmentation\r\n",
        "if unet_2d == False:\r\n",
        "  #kernel size\r\n",
        "  kc, kh, kw = 32,64,64\r\n",
        "  #stride  \r\n",
        "  dc, dh, dw = 32,64,64\r\n",
        "\r\n",
        "batch_size = 16\r\n",
        "num_workers = 0\r\n",
        "\r\n",
        "#Define type of optimizer as either 'Adam' or 'SGD'\r\n",
        "optimizer_type = 'Adam' \"\"\"adjust the learning rate in the\r\n",
        "                           \"Specify the loss function and optimizer\" section\"\"\"\r\n",
        "\r\n",
        "\"\"\"If you are willing to find the maximum learning rate using the One Cycle \r\n",
        "learning rate policy set lr_find to True\"\"\"\r\n",
        "lr_find = False   \r\n",
        "n_epochs = 1\r\n",
        "inference_only = False #If you wish to use the pretrained model set to True\r\n",
        "\r\n",
        "threshold = 0.5  # Threshold value to create binary image \r\n",
        "\r\n",
        "split_ratio = [0.70, 0.10, 0.20]   # A list of the (train,val,test) split ratio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyLOytsVEGcQ"
      },
      "source": [
        "##Volume resize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUq7BUXeoKiI"
      },
      "source": [
        "#Create a grid (d1,d2,d3) to be used for volume resizing\n",
        "meshx, meshy, meshz = torch.meshgrid((d1, d2, d3))\n",
        "grid = torch.stack((meshx, meshy, meshz), 3)\n",
        "grid = grid.unsqueeze(0) # add batch dim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8NHi6YJXWXX"
      },
      "source": [
        "#Resize patients' CT and Masks using the same grid\n",
        "for patient in patient_image_cnt_CT:\n",
        "    volume_composer(patient, patient_image_cnt_CT, patient_path_list, grid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zPv9WNkVCEr"
      },
      "source": [
        "###Compare the resized volume slices with their counterpart in the original dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdpKTgYG8-af"
      },
      "source": [
        "#sample patient \n",
        "p = 'Patient0067'\n",
        "#sample slice number in the resized volume\n",
        "n = 60\n",
        "#n_o is approximately the slice number in the original volume\n",
        "n_o = str(int( n * patient_image_cnt_Mask[p] / d3.numpy().size))\n",
        "im = torch.load('/content/data3D/' + p + '_CT.pt')\n",
        "m = torch.load('/content/data3D/' + p + '_Mask.pt')\n",
        "im = im.numpy()\n",
        "m = m.numpy()\n",
        "im = np.squeeze(im)[:,:,n]\n",
        "m = np.squeeze(m)[:,:,n]\n",
        "im_o = Image.open('/content/data/' + p + '/CT/CT_' + n_o + '.png')\n",
        "m_o = Image.open('/content/data/' + p + '/Masks/M_' + n_o + '.png')\n",
        "im_o_t = np.transpose(im_o)\n",
        "m_o_t = np.transpose(m_o)\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.subplot(2,3,1)\n",
        "plt.imshow(im, cmap=\"gray\", interpolation= None)\n",
        "plt.title('resized CT')\n",
        "plt.subplot(2,3,2)\n",
        "plt.imshow(m, cmap=\"gray\", interpolation= None)\n",
        "plt.title('resized annotation mask')\n",
        "plt.subplot(2,3,3)  \n",
        "plt.imshow(im, cmap=\"gray\", interpolation= None)\n",
        "plt.imshow(m, cmap=\"jet\", alpha = 0.3, interpolation= None)\n",
        "plt.subplot(2,3,4)\n",
        "plt.imshow(im_o_t, cmap=\"gray\", interpolation= None)\n",
        "plt.title('original CT transposed')\n",
        "plt.subplot(2,3,5)\n",
        "plt.imshow(m_o_t, cmap=\"gray\", interpolation= None)\n",
        "plt.title('original annotation mask transposed')\n",
        "plt.subplot(2,3,6)  \n",
        "plt.imshow(im_o_t, cmap=\"gray\", interpolation= None)\n",
        "plt.imshow(m_o_t, cmap=\"jet\", alpha = 0.3, interpolation= None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IV9sLTI2PI9e"
      },
      "source": [
        "#remove \"data\" directory as we don't need it anymore\r\n",
        "!rm -r data "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmQt1_J7BsM_"
      },
      "source": [
        "###Create and save slices for 2D training based on the resized volumes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmigZX7mCLHH"
      },
      "source": [
        "if unet_2d:\n",
        "    !mkdir data/\n",
        "    slice_cnt = d3.numpy().size\n",
        "    ##Recreate a dictionary of patients CT and Masks paths\n",
        "    patient_path_list = {}\n",
        "    patient_path_list['CT'] = {}\n",
        "    patient_path_list['Masks'] = {}\n",
        "\n",
        "    for p in patient_image_cnt_CT.keys():\n",
        "        path_CT_folder = os.path.join('data', p, 'CT')\n",
        "        path_mask_folder = os.path.join('data', p, 'Masks')\n",
        "        os.makedirs(path_CT_folder)\n",
        "        os.makedirs(path_mask_folder)\n",
        "        #load 3D CT image\n",
        "        im =  torch.load('/content/data3D/' + p + '_CT.pt')\n",
        "        #load 3D mask \n",
        "        m =  torch.load('/content/data3D/' + p + '_Mask.pt')\n",
        "        ## Transform CT and mask to numpy array\n",
        "        im = im.numpy().squeeze(0).squeeze(0)\n",
        "        m = m.numpy().squeeze(0).squeeze(0)\n",
        "        for s in range(slice_cnt):\n",
        "            #create a 3digit label for each slice\n",
        "            label = '{:03d}'.format(s)\n",
        "            \"\"\"\n",
        "            save each patients CT and Mask in a designated folder, e.g. patient\n",
        "            17, CT slice 100 would be '/content/data/Patient0017/CT/CT_100.png'\n",
        "            \"\"\"\n",
        "            ct_path  = os.path.join('/content', 'data', p, 'CT', 'CT_'+ label +\n",
        "                                    '.png' )\n",
        "            mask_path = os.path.join('/content', 'data', p, 'Masks', \"M_\" + \n",
        "                                     label + '.png' )    \n",
        "            cv2.imwrite(ct_path, im[:, :, s])\n",
        "            cv2.imwrite(mask_path, m[:, :, s])     \n",
        "        patient_path_list ['CT'][p] = sorted(glob.glob('/content/data/' + p +\n",
        "                                                       '/CT/*.png'))        \n",
        "        patient_path_list ['Masks'][p] = sorted(glob.glob('/content/data/' +\n",
        "                                                          p + '/Masks/*.png'))   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJfg5TrJwBIb"
      },
      "source": [
        "####Check the 2D png files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkpY4N34wGhN"
      },
      "source": [
        "if unet_2d:\n",
        "    #for patient 17,47,77 check the CT and mask slice number 100\n",
        "    CT_0 = Image.open('/content/data/Patient0017/CT/CT_100.png')\n",
        "    CT_1 = Image.open('/content/data/Patient0047/CT/CT_100.png')\n",
        "    CT_2 = Image.open('/content/data/Patient0077/CT/CT_100.png')\n",
        "    slice_0 = Image.open('/content/data/Patient0017/Masks/M_100.png')\n",
        "    slice_1 = Image.open('/content/data/Patient0047/Masks/M_100.png')\n",
        "    slice_2 = Image.open('/content/data/Patient0077/Masks/M_100.png')\n",
        "    plt.figure(figsize=[15,15])\n",
        "    plt.subplot(3,3,1)\n",
        "    plt.imshow(CT_0, cmap=\"gray\", interpolation= None)\n",
        "    plt.subplot(3,3,2)\n",
        "    plt.imshow(CT_1, cmap=\"gray\", interpolation= None)\n",
        "    plt.subplot(3,3,3)\n",
        "    plt.imshow(CT_2, cmap=\"gray\", interpolation= None)\n",
        "    plt.subplot(3,3,4 )\n",
        "    plt.imshow(slice_0, cmap=\"gray\", interpolation= None)\n",
        "    plt.subplot(3,3,5 )\n",
        "    plt.imshow(slice_1, cmap=\"gray\", interpolation= None)\n",
        "    plt.subplot(3,3,6 )\n",
        "    plt.imshow(slice_2, cmap=\"gray\", interpolation= None)\n",
        "    plt.subplot(3,3,7)\n",
        "    plt.imshow(CT_0, cmap=\"gray\", interpolation= None)\n",
        "    plt.imshow(slice_0, cmap=\"jet\", alpha =0.3, interpolation= None)\n",
        "    plt.subplot(3,3,8)\n",
        "    plt.imshow(CT_1, cmap=\"gray\", interpolation= None)\n",
        "    plt.imshow(slice_1, cmap=\"jet\", alpha =0.3, interpolation= None)\n",
        "    plt.subplot(3,3,9)\n",
        "    plt.imshow(CT_2, cmap=\"gray\", interpolation= None)\n",
        "    plt.imshow(slice_2, cmap=\"jet\", alpha =0.3, interpolation= None)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBymOSATSPv7"
      },
      "source": [
        "##Patients' ID partitioning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGIistiE-ZQy"
      },
      "source": [
        "#stratify split patients into 3 sets: train, valid, test\n",
        "part = partitioning([*patient_image_cnt_CT.keys()], split_ratio = [0.7,0.1,0.2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-M5jBdrYwbX"
      },
      "source": [
        "###Data partitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egI2PO-u-ZC8"
      },
      "source": [
        "if unet_2d:\n",
        "    \"\"\"\n",
        "    2D data partitioning: Create 3 partitions (train, valid,test) where each are\n",
        "    dictionaries of CT and mask paths.\n",
        "    \"\"\"\n",
        "    partition_train = {}\n",
        "    partition_train ['CT'] = []\n",
        "    partition_train ['Masks'] = []\n",
        "    for p in part['train']:\n",
        "        partition_train ['CT'].extend(patient_path_list ['CT'][p] )\n",
        "        partition_train ['Masks'].extend(patient_path_list ['Masks'][p] )\n",
        "    partition_valid = {}\n",
        "    partition_valid ['CT'] = []\n",
        "    partition_valid ['Masks'] = []\n",
        "    for p in part['valid']:\n",
        "        partition_valid ['CT'].extend(patient_path_list ['CT'][p] )\n",
        "        partition_valid ['Masks'].extend(patient_path_list ['Masks'][p])        \n",
        "    partition_test= {}\n",
        "    for p in part['test']:\n",
        "        partition_test [p] = {}  \n",
        "        partition_test[p] ['CT'] = []\n",
        "        partition_test[p] ['Masks'] = []\n",
        "        partition_test[p] ['CT'].extend(patient_path_list ['CT'][p])\n",
        "        partition_test[p] ['Masks'].extend(patient_path_list ['Masks'][p])\n",
        "else:\n",
        "    \"\"\"\n",
        "    Create subvolumes (patches) for each patient's CT and mask, and save the\n",
        "    patches (torch tensors) in the corresponding dictionary, i.e. based on\n",
        "    the patient's partition. The 'test' patches will be created seperately per \n",
        "    patient in the \"Get the inference performance metrics\" section.\n",
        "    \"\"\"\n",
        "    CT_patches = {}\n",
        "    mask_patches ={}\n",
        "    for p in ['train', 'valid']:\n",
        "        CT_patches[p], mask_patches[p] = patch_creator(part[p],\n",
        "                                                       kw, kh, kc, dw, dh, dc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2YrfKjJ6-Ea"
      },
      "source": [
        "## Constructing the dataset and the dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4Nh_sWH0SNT"
      },
      "source": [
        "# Construct the dataset\n",
        "if unet_2d:\n",
        "    dataset_train = Pancreas_2D_dataset (partition_train, augment= True)\n",
        "    dataset_valid = Pancreas_2D_dataset (partition_valid, augment= False)        \n",
        "    dataset_test ={}\n",
        "    # The test partition is arranged per patient\n",
        "    for p in partition_test:\n",
        "      dataset_test[p] = Pancreas_2D_dataset (partition_test[p], augment = False)\n",
        "else:\n",
        "    #\n",
        "    dataset_train = Pancreas_3D_dataset (CT_patches['train'], \n",
        "                                         mask_patches['train'], augment= True)\n",
        "    dataset_valid = Pancreas_3D_dataset (CT_patches['valid'],\n",
        "                                         mask_patches['valid'], augment= False)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tl_kTvfpdr5"
      },
      "source": [
        "\"\"\"\n",
        "Generators (data loaders) for the train and valid sets. The test loader is \n",
        "in the \"Generate predictions\" section.\n",
        "\"\"\"\n",
        "loaders={}\n",
        "loaders['train'] = torch.utils.data.DataLoader(dataset_train, \n",
        "                                               batch_size=batch_size, \n",
        "                                               shuffle=True, \n",
        "                                                num_workers=num_workers)\n",
        "loaders['valid'] = torch.utils.data.DataLoader(dataset_valid, \n",
        "                                               batch_size=batch_size, \n",
        "                                               shuffle=False, \n",
        "                                               num_workers=num_workers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHj6_qmY1M8O"
      },
      "source": [
        "###Get sample batch from loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjERYnrz_cUF"
      },
      "source": [
        "batch = iter(loaders['valid'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjIsghCWIm5l"
      },
      "source": [
        "image, mask = next(batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roYz13YsyfDZ"
      },
      "source": [
        "if unet_2d:\n",
        "    for im, m in zip(image, mask):\n",
        "        im = im.numpy()\n",
        "        m = m.numpy()\n",
        "        im = np.squeeze(im)\n",
        "        m = np.squeeze(m)\n",
        "        plt.figure()\n",
        "        plt.subplot(1,3,1)\n",
        "        plt.imshow(im, cmap=\"gray\", interpolation= None)\n",
        "        plt.subplot(1,3,2)\n",
        "        plt.imshow(m, cmap=\"gray\", interpolation= None)\n",
        "        plt.subplot(1,3,3)  \n",
        "        plt.imshow(im, cmap=\"gray\", interpolation= None)\n",
        "        plt.imshow(m, cmap=\"jet\", alpha = 0.3, interpolation= None)\n",
        "else:\n",
        "    for im, m in zip(image, mask):\n",
        "        #transfer C x D x H x W to C x W x H x D \n",
        "        im = im.permute(0,3,2,1)\n",
        "        m = m.permute(0,3,2,1)\n",
        "        im = im.numpy()\n",
        "        m = m.numpy()\n",
        "        im = np.squeeze(im)\n",
        "        m = np.squeeze(m)\n",
        "        plt.figure(figsize=(8,8))\n",
        "        plt.subplot(4,3,1)\n",
        "        plt.imshow(im[:,:,20], cmap=\"gray\", interpolation= None)\n",
        "        plt.subplot(4,3,2)\n",
        "        plt.imshow(m[:,:,20], cmap=\"gray\", interpolation= None)\n",
        "        plt.subplot(4,3,3)\n",
        "        plt.imshow(im[:,:,20], cmap=\"gray\", interpolation= None)\n",
        "        plt.imshow(m[:,:,20], cmap=\"jet\", alpha = 0.3, interpolation= None)\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzefG1faoFJa"
      },
      "source": [
        "##Obtain Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EooXLUwR3ZYD"
      },
      "source": [
        "# instantiate the unet\n",
        "if unet_2d:\n",
        "    model = UNet_2D(1,1,32,0.2)\n",
        "else:\n",
        "    model = UNet_3D(1,1,32,0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpxqCi7Q3eEy"
      },
      "source": [
        "# if GPU is available, move the model to GPU\n",
        "if train_on_gpu:\n",
        "    model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuX9of7asY2J"
      },
      "source": [
        "if unet_2d:\n",
        "  summary(model, (1,256, 256), batch_size = batch_size)\n",
        "else:\n",
        "  summary(model, (1, 32, 64, 64), batch_size = batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4bhUDBZoRb8"
      },
      "source": [
        "##Specify the loss function and optimizer\r\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tw3DYt4oWbi"
      },
      "source": [
        "criterion = TverskyLoss(1e-8,0.3,.7)\n",
        "#lr_find = False\n",
        "# Optimizer\n",
        "if optimizer_type == 'SGD':\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "else:\n",
        "    optimizer = optim.Adam(model.parameters(), lr = .005)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sezu2W2Q8H9P"
      },
      "source": [
        "###Learning rate scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XoLRQq9FTet"
      },
      "source": [
        "\"\"\"\n",
        "If lr_find is True, after running this cell, assign the scheduler's max_lr to \n",
        "the suggested maximum lr and then set lr_find to False in the \"Set the parameters\"\n",
        "section. Set the lr in the optimizer 1/10 of max_lr. Then re_run the code. \n",
        "\"\"\"\n",
        "if lr_find == False:\n",
        "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.08, steps_per_epoch=len(loaders['train']), epochs=n_epochs)        #(optimizer, max_lr=0.01, total_steps=4000)\n",
        "else:\n",
        "    #https://github.com/davidtvs/pytorch-lr-finder\n",
        "    desired_batch_size, real_batch_size = batch_size, batch_size\n",
        "    accumulation_steps = desired_batch_size // real_batch_size\n",
        "    lr_finder = LRFinder(model, optimizer, criterion, device='cuda')\n",
        "    lr_finder.range_test(loaders['train'], end_lr=1, num_iter=100, step_mode='exp')\n",
        "    lr_finder.plot() # to inspect the loss-learning rate graph\n",
        "    lr_finder.reset() # to reset the model and optimizer to their initial state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2AgCocVn9ym"
      },
      "source": [
        "##Train and validate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrXNmYKzfZl6"
      },
      "source": [
        "if inference_only == False:\n",
        "  # train the model\n",
        "  if unet_2d:\n",
        "      model = train_2D(n_epochs, loaders, model, optimizer, criterion, \n",
        "                       train_on_gpu, performance_metrics, 'model.pt', threshold)\n",
        "  else:\n",
        "      model = train_3D(n_epochs, loaders, model, optimizer, criterion, \n",
        "                       train_on_gpu, performance_metrics, 'model.pt', threshold)\n",
        "else:\n",
        "  # load the model that got the best validation accuracy or a trained model\n",
        "  model.load_state_dict(torch.load('model.pt'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qe9QObfWdJkv"
      },
      "source": [
        "# plot the variation of train and validation losses vs n_epochs\n",
        "loss=pd.read_csv('performance_metrics.csv',header=0,index_col=False)\n",
        "plt.plot(loss['epoch'], loss['Training Loss'], 'r', loss['epoch'],\n",
        "         loss['Validation Loss'],'g')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(labels=['Train','Valid'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVxiV_gScLqi"
      },
      "source": [
        "# plot the generalization error vs n_epochs\n",
        "plt.plot(loss['epoch'],loss['Training Loss']-loss['Validation Loss'])\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('Generalization Error')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lilu4XbXpGFD"
      },
      "source": [
        "##Generate predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9aojD-Wxwua"
      },
      "source": [
        "###Get the inference performance metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxWW35oQxwGZ"
      },
      "source": [
        "if unet_2d:\r\n",
        "    df =get_inference_performance_metrics_2D(model, part['test'], dataset_test, batch_size, train_on_gpu, threshold)\r\n",
        "else:\r\n",
        "    df = get_inference_performance_metrics_3D(model, part['test'], Pancreas_3D_dataset, batch_size, train_on_gpu, threshold, kw, kh, kc, dw, dh, dc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaEIc073hj2G"
      },
      "source": [
        "#metrics per patient\r\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5522j0vhjpW"
      },
      "source": [
        "#The inference performance metrics stats\r\n",
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MK3GKAMP-RJh"
      },
      "source": [
        "###Visualize the inference results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGvcGQI5pNS0"
      },
      "source": [
        "#sample patient 57\n",
        "patient = 'Patient0057'\n",
        "if unet_2d:\n",
        "    visualize_patient_prediction_2D(model, patient, dataset_test, batch_size, \n",
        "                                    train_on_gpu, threshold) \n",
        "else: \n",
        "    visualize_patient_prediction_3D(model, patient, Pancreas_3D_dataset, \n",
        "                                    batch_size, train_on_gpu, threshold,\n",
        "                                    kw, kh, kc, dw, dh, dc)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQYdSEEjfhVN"
      },
      "source": [
        "!pip install pipreqs\r\n",
        "!pipreqs "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}